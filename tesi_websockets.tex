 %\documentclass[12pt,a4paper,oneside]{report}

\documentclass[12pt,a4paper,openright,twoside]{report}
\usepackage[hmarginratio=1:1]{geometry}
\usepackage[italian]{babel}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{listings}
\usepackage{upquote}
\usepackage{framed,xcolor,verbatim}
\usepackage{emptypage} %removes header and footers from empty pages
\usepackage{amsmath}
\usepackage{url}
\def\UrlBreaks{\do\/\do-}
\usepackage{breakurl}
\usepackage[breaklinks]{hyperref}
\definecolor{lightgray}{rgb}{0.95, 0.95, 0.95}
\definecolor{darkgray}{rgb}{0.4, 0.4, 0.4}
\definecolor{editorGray}{rgb}{0.98, 0.98, 0.98}
\definecolor{editorOcher}{HTML}{FF7F00}
\definecolor{green}{HTML}{0D9E0D}
\definecolor{orange}{HTML}{CF7B2F}
\definecolor{red}{HTML}{D53235}
\definecolor{olive}{rgb}{0.17,0.59,0.20}
\definecolor{brown}{rgb}{0.69,0.31,0.31}
\definecolor{purple}{HTML}{BC5298}
\definecolor{lightblue}{rgb}{0.1,0.57,0.7}
\definecolor{lightred}{rgb}{1,0.4,0.5}

% JavaScriptnpm sta
\lstdefinelanguage{JavaScript}{
  keywords={break, case, catch, continue, debugger, default, delete, do, else, false, finally, for, function, if, in, instanceof, new, null, return, switch, true, try, typeof, var, void, while, with, const, let},
  ndkeywords={class, export, boolean, throw, implements, import, this},
  morecomment=[s]{/*}{*/},
  morecomment=[l]//,
  morestring=[b]",
  morestring=[b]`,
  morestring=[b]',
  % Code design
  identifierstyle=\color{black},
  keywordstyle=\color{purple}\bfseries,
  ndkeywordstyle=\color{red}\bfseries,
  stringstyle=\color{green}\ttfamily,
  commentstyle=\color{darkgray}\ttfamily,
}
\lstset{
   language=JavaScript,
   backgroundcolor=\color{editorGray},
   extendedchars=true,
   basicstyle=\footnotesize\ttfamily,
   showstringspaces=false,
   showspaces=false,
   numbers=left,
   numberstyle=\tiny,
   numbersep=9pt,
   frameround=tttt,
   frame=single,
   tabsize=3,
   breaklines=true,
   showtabs=false,
   captionpos=b
}

%\usepackage[latin1]{inputenc}
\usepackage{indentfirst}
\usepackage{fancyhdr}
\usepackage{natbib}
\usepackage{newlfont}
\usepackage{hyperref}
\usepackage{url}

\definecolor{shadecolor}{rgb}{.9, .9, .9}

\newenvironment{code}%
   {\snugshade\verbatim}%
   {\endverbatim\endsnugshade}

\usepackage{graphicx}
\usepackage{svg}
\usepackage{afterpage}

\newcommand\blankpage{%
    \null
    \thispagestyle{empty}%
    \addtocounter{page}{-1}%
    \newpage}

%\usepackage{showkeys} serve per mostrare le etichette, va tolta per la versione definitiva;
%\linespread{1.3}
\oddsidemargin=0pt
\textwidth=450pt
%\hyphenation{} %serve per la sillabazione
\hypersetup{
    colorlinks,
    citecolor=black,
    filecolor=black,
    linkcolor=black,
    urlcolor=black
}

\setlength{\parindent}{0pt}


%\pagestyle{fancy}\addtolength{\headwidth}{20pt}
\renewcommand{\chaptermark}[1]{\markboth{\thechapter.\ #1}{}}
\renewcommand{\sectionmark}[1]{\markright{\thesection \ #1}{}}
%\rhead[\fancyplain{}{\bfseries\leftmark}]{\fancyplain{}{\bfseries\thepage}}
\cfoot{}

\begin{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
						% Frontespizio
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{titlepage}
\begin{center}
{{\Large{\textsc{Alma Mater Studiorum $\cdot$ Universit\`a di
Bologna}}}} \rule[0.1cm]{15.8cm}{0.1mm}
\rule[0.5cm]{15.8cm}{0.6mm}
{\small{\bf SCUOLA DI SCIENZE\\
Corso di Laurea in Informatica }}
\end{center}
\vspace{40mm}
\begin{center}
{\LARGE{\bf Resource-centric push model}}\\
\vspace{3mm}
{\LARGE{\bf over WebSockets}}\\
\end{center}
\vspace{40mm}
\par
\noindent
\begin{minipage}[t]{0.47\textwidth}
{\large{\bf Relatore:\\
Chiar.mo Prof.\\
Fabio Vitali}}
\end{minipage}
\hfill
\begin{minipage}[t]{0.47\textwidth}\raggedleft
{\large{\bf Presentata da:\\
Filippo Vigani}}
\end{minipage}
\vspace{30mm}
\begin{center}
{\large{\bf Sessione I\\%inserire il numero della sessione in cui ci si laurea
Anno Accademico 2018-2019}}%inserire l'anno accademico a cui si è iscritti
\end{center}
\end{titlepage}
\newgeometry{margin=1.5in}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
							% Dedica
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\clearpage{\pagestyle{empty}\cleardoublepage}
\thispagestyle{empty}
\vspace*{\stretch{1}}
\normalsize                                  
\begin{flushright}
\em
\itshape Alla mia famiglia, che mi ha spinto ad intraprendere questa strada,\\
e ai miei amici, senza i quali non avrei continuato a percorrerla.

\end{flushright}
\vspace{\stretch{2}}

\cleardoublepage
\linespread{1.3}

%\textwidth=345.0pt

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
							% Indice
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\pagenumbering{roman}\normalsize
\clearpage{\pagestyle{empty}\cleardoublepage}
\tableofcontents
%\rhead[\fancyplain{}{\bfseries\leftmark}]{\fancyplain{}{\bfseries\thepage}}
%\lhead[\fancyplain{}{\bfseries\thepage}]{\fancyplain{}{\bfseries INDICE}}

\listoffigures
\addcontentsline{toc}{chapter}{Elenco delle figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
							% Introduzione
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter*{Introduzione}
%\rhead[\fancyplain{}{\bfseries INTRODUZIONE}]{\fancyplain{}{\bfseries\thepage}}
%\lhead[\fancyplain{}{\bfseries\thepage}]{\fancyplain{}{\bfseries INTRODUZIONE}}
\addcontentsline{toc}{chapter}{Introduzione}
Quando si sviluppa un’applicazione web, si deve considerare che meccanismo di data delivery utilizzare. Spesso si vuole sviluppare un’applicazione che lavori con dati in tempo reale: può essere una dashboard con l’andamento di un mercato azionario, o una console di un servizio backend su cui lavorano più utenti, o ancora un semplice calendario condiviso per la gestione di appuntamenti.

\bigskip

Per molto tempo l’unica modalità per reperire i dati da un web browser è stata tramite \textit{client pull}, ovvero il client si occupa di richiedere una risorsa, e richiedere se la risorsa stessa sia stata modificata.

\bigskip

Con l’implementazione dei \textit{WebSocket} nella maggior parte dei browser, la situazione cambia. Si apre la possibilità di ricevere dati tramite \textit{server push}, senza dover periodicamente richiedere una risorsa, ma lasciando al server l’onere di notificare i client dell’avvenuta modifica della risorsa.

\bigskip

Tuttavia i WebSocket rimangono un’implementazione di basso livello, e lavorarci su applicazioni di alto livello, dove l’architettura e la separation of concerns è un punto focale, risulta complesso.

\bigskip

La soluzione proposta permette in modo semplice ed intuitivo di rimanere in ascolto di una risorsa come se fosse un endpoint REST, e ogni qualvolta questa risorsa venga aggiornata, essere notificati del nuovo contenuto, senza doversi preoccupare di una gestione efficiente delle risorse.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
							% Real-time web applications
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Real-time web applications}
\pagestyle{fancy}
\lhead[\rmfamily\thepage]{\fancyplain{}{\itshape\nouppercase\rightmark}} % respectively left page inner and right page inner 
\rhead[\fancyplain{}{\itshape\nouppercase\leftmark}]{\rmfamily\thepage} % respectively left page outer and right page outer 
%\rhead[\fancyplain{}{\bfseries\thepage}]{\fancyplain{}{\bfseries\rightmark}}
%\lhead[\fancyplain{}{\bfseries\thepage}]{\fancyplain{}{\bfseries\leftmark}}
\pagenumbering{arabic}

Nello sviluppo di applicazioni web moderne spesso si ha la necessità di aggiornare parti dell’interfaccia in modo che rispecchino delle risorse non presenti localmente in tempo reale. Si pensi per esempio ad un’applicazione che deve visualizzare i dati dello stock market, o ad un social network, o ad un calendario per la gestione degli appuntamenti, o ancora ad una semplice dashboard di gestione aziendale. 

\bigskip

In tutti questi casi, poter vedere le modifiche effettuate da terzi sulle stesse risorse in real-time è essenziale o migliora di gran lunga la user experience. Le applicazioni real-time stanno gradualmente dominando l’internet in quanto forniscono un perfetto equilibrio di informazioni, funzionalità, contenuto e interattività che portano ad aumentare lo user engagement.

%%%%%%%%%%%%%%%%%%%%%%%%%
			% Tecniche di sviluppo
%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Tecniche di sviluppo}

Con applicazioni \textit{real-time} intendiamo applicazioni che permettano di ricevere e visualizzare degli aggiornamenti che risiedono su un server nel minor tempo possibile. Da una definizione così banale, spuntano in realtà una serie di questioni importanti per quanto concerne sia le tecnologie per implementarle, che le tecniche utilizzate che la gestione delle risorse.

\bigskip

Gli sviluppatori web, fino a qualche anno fa, per ottenere dei risultati simili hanno dovuto sfruttare diverse tecniche che aggirassero le limitazioni dei browser. Infatti l’unico modo di ricevere dati per un browser era quello di inviare una richiesta al server, e ricevere una risposta. Ciò significa che il client non aveva modo di essere notificato in caso la risorsa richiesta venisse modificata.

%%%%%%%%%%%%%%%%%%%%%%%%%
			% Client pull
%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Client pull}\label{sec_clientpull}

Questo stile di comunicazione ove la richiesta è originata dal client e corrisposta dal server è chiamato \textit{client pull}. Il client pull forma la base per la comunicazione tra un browser e un server tramite il protocollo HTTP, e su di esso si sono costruiti una serie di stili architetturali per fornire interoperabilità tra web services in maniera prestabilita. Per esempio, uno degli stili più utilizzati è REST (REpresentational State Transfer), che stabilisce che i web services devono permettere ad altri sistemi di richiedere l’accesso o la manipolazione di rappresentazioni testuali di risorse web usando un insieme predefinito di operazioni stateless.

\bigskip

Un protocollo stateless prevede che il server non mantenga nessuna informazione riguardante la connessione attiva del client tra una richiesta e l’altra. Non mantenendo alcun tipo di informazione sulla sessione, ne consegue che per verificare se una risorsa è stata aggiornata rispetto a quella salvata da un browser in precedenza, è necessario richiedere la stessa risorsa e compararla con la precedente.

%%%%%%%%%%%%%%%%%%%%%%%%%
		% Polling e long polling
%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Polling e long polling}

Una delle tecniche largamente utilizzate per verificare se una risorsa, web o meno, sia stata modificata è appunto richiedere la stessa risorsa a intervalli regolari, e confrontarla con la precedente. Questa tecnica nella letteratura è chiamata polling. Nell’ambito dei web services e di HTTP, si possono distinguere due tipi di polling: Polling semplice e long polling
\begin{description}
\item Nel \textbf{polling semplice} la risorsa viene richiesta periodicamente e il server risponde immediatamente con la risorsa richiesta. Ad un livello più basso, viene aperta una connessione, inviato un messaggio dal client al server contenente la richiesta, inviato un messaggio di risposta dal server al client contenente la risorsa, e la connessione viene chiusa. Successivamente, dopo un periodo di polling prestabilito, si ripete.
Un esempio di utilizzo di polling client side potrebbe essere il seguente:
\lstinputlisting[caption=Client side XHR polling example]{snippets/polling_sample.js}

\begin{figure}[htbp]
\centering
\includegraphics[width=.8\textwidth]{assets/polling.png}
\caption{Polling}
\end{figure}

\item Nel caso del \textbf{long polling}, conosciuto anche come \textit{hanging GET} o \textit{COMET}, invece, il client invia una richiesta ad una risorsa specifica. Il server, invece di rispondere immediatamente, tiene aperta la connessione fintanto che la risorsa non viene aggiornata o finché una soglia di timeout viene superata. Quando sono presenti nuovi dati, il server risponde alla richiesta chiudendo la connessione di conseguenza. Dopodiché il client richiede nuovamente la stessa risorsa e rimane in attesa.
Questo flusso può essere implementato come l'esempio seguente:
\lstinputlisting[caption=Client side XHR long polling example]{snippets/longpolling_sample.js}

\begin{figure}[htbp]
\centering
\includegraphics[width=.8\textwidth]{assets/long_polling.png}
\caption{Long polling}
\end{figure}

A differenza del polling semplice, dove l’implementazione riguarda solo la parte client, e il server espone un semplice endpoint REST, nel long polling il server deve supportare questo tipo di interazione con il client. Infatti, oltre ad esporre l'endpoint REST, dovrà offrire un endpoint che si occupa di mantenere il client in attesa, ed inviare la risposta solo una volta che viene aggiornata la risorsa. Inoltre, dovrà gestire lo stato di connessioni multiple, ed implementare strategie per preservare lo stato delle sessioni quando si utilizzano più server e load balancers.

\end{description}

\subsection{Problematiche}
Entrambe le tecniche di polling sono dei workaround dovute alle storiche limitazioni dei browser e di HTTP, e dunque presentano delle problematiche. 
% Consumo di banda e traffico dati
\subsubsection{Consumo di banda e traffico dati}
Poiché il polling richiede ad intervalli regolari la stessa risorsa, spreca traffico dati per passare sia la richiesta della risorsa stessa, che per ricevere il payload effettivo. In particolare per ogni richiesta HTTP, deve essere stabilita una nuova connessione, si deve fare il parsing degli header HTTP, si deve presumibilmente reperire i dati da un database, e infine inviare i dati al client.

% Ritardo
\subsubsection{Ritardo}
Per limitare questo consumo, si cerca di trovare un equilibrio riducendo la frequenza di poll. Ma così facendo, risulta che per ricevere un aggiornamento di una risorsa, il client potrebbe aspettare fino alla durata dell’intervallo di tempo tra una richiesta e la successiva.

% Incoerenza dei dati
\subsubsection{Incoerenza dei dati}
Nel caso del long polling, la risorsa viene inviata presumibilmente appena subisce delle modifiche. Tuttavia nel lasso di tempo che passa tra quando il client riceve una risposta, ed effettua la nuova richiesta da tenere aperta, la risorsa stessa potrebbe essere modificata. In tal caso, il server non ha nessuna connessione in sospeso con il client, ed esso perderebbe l’aggiornamento. Alternativamente si potrebbe pensare di mantenere una coda di messaggi da inviare ad un client, ma il throughput di questa coda è determinato dal tempo impiegato a stabilire una nuova connessione, portando una serie di aggiornamenti frequenti ad essere inviati con un ritardo.

% Performance e scalabilità
\subsubsection{Performance e scalabilità}
Con l’aumentare del numero di client connessi, il numero di richieste rapportate al tempo invece di incrementare linearmente si moltiplica, in quanto ogni client per la stessa risorsa non effettuerà una singola richiesta, ma richieste multiple. Ciò rende i sistemi che implementano polling difficili da scalare e poco performanti.

%%%%%%%%%%%%%%%%%%%%%%%%%
			% Server push
%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Server push}\label{sec_serverpush}
A differenza del client pull, il server push è uno stile di comunicazione che prevede che sia il server ad inviare ad un client dei dati, senza che una richiesta venga necessariamente inviata in precedenza da parte del client. I servizi che supportano server push, spesso si basano su delle preferenze espresse dal client in precedenza. Questo modello è chiamato publish/subscribe. Un client esprime di voler ricevere gli aggiornamenti ad una risorsa o “channel”, e il server si occupa di inviare la risorsa a tale channel ogni volta che viene modificata.

\bigskip

Prima di HTML5, non era possibile implementare un modello publish/subscribe che funzionasse sulle applicazioni web, se non tramite astrazioni basate su polling. Con l’arrivo di HTML living standard e diverse tecnologie web, è ora possibile implementare sistemi connection-based per lo scambio di dati in real-time.

%%%%%%%%%%%%%%%%%%%%%%%%%
    % Server Sent Events
%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Server Sent Events}
I \textit{Server Sent Events (SSE)} sono una tecnologia push che permette ad un browser di ricevere aggiornamenti da un server tramite una connessione HTTP basandosi su una comunicazione simplex\footnote{in un'unica direzione}. L'API che offre questa funzionalità, chiamata \textit{EventSource API}, è standardizzata dal W3C come parte di HTML5.

Il flusso di una comunicazione basata su EventSource è il seguente\cite{eventsource_api}, sintetizzato in figura \ref{fig:server_sent_events}.

\begin{enumerate}
  \item Il client tramite la chiamata API \lstinline{new EventSource('/api/myEndpoint')} apre una nuova connessione HTTP.
  \item Il client registra le callback agli eventi \lstinline{onmessage}, \lstinline{onopen} e \lstinline{onerror}.
  \item Il server risponde alla prima richiesta specificando nell'header \lstinline{Content-Type} il tipo \lstinline{text/event-stream}.
  \item Il client, se supporta la EventSource API, mantiene la connessione aperta in attesa di nuovi messaggi.
  \item Il server può dunque inviare quando desidera un nuovo messaggio, finché la connessione non viene chiusa da una delle due parti.
\end{enumerate}

\begin{figure}[!htbp]
\centering
\includegraphics[width=.6\textwidth]{assets/server_sent_events.png}
\caption{Server Sent Events Flow}
\label{fig:server_sent_events}
\end{figure}

Un esempio di utilizzo di quest'API è il seguente:
\lstinputlisting[caption=Client side EventSource example]{snippets/eventsource_sample.js}

La limitazione di questa tecnologia è che una volta aperta una connessione, il client non potrà sfruttare la stessa per inviare ulteriori messaggi. Ciò significa che per rimanere in ascolto di diverse risorse in instanti differenti, sarà necessario aprire più connessioni. Se invece il server supporta HTTP/2, SSE potrà sfruttare il multiplexing offerto da HTTP/2 automaticamente.
Inoltre, al momento di questa stesura, nessuna versione di Internet Explorer e nessuna versione precedente alla 75 di Edge supportano i SSE\cite{sse_support_caniuse}.

%%%%%%%%%%%%%%%%%%%%%%%%%
		% WebSockets
%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{WebSockets}
I \textit{WebSocket} sono un protocollo che permette una comunicazione full-duplex\footnote{in entrambe le direzioni e contemporaneamente} mediante una singola connessione TCP.
L'RFC 6455 afferma che WebSocket è progettato in modo da funzionare attraverso le porte HTTP 80 e 433 e di supportare proxy e intermediari HTTP, rendendolo dunque compatibile con il protocollo HTTP\cite{websockets_rfc}. Per poter essere compatibile, l'handshake tramite WebSocket fa uso dell'header \lstinline{Upgrade} di HTTP per cambiare protocollo da HTTP a WebSocket. Ciò è possibile perché entrambi i protocolli fanno parte dell'application layer nel modello OSI e dipendono da TCP.

\bigskip

Nei browser i WebSocket possono essere utilizzati mediante la \textit{WebSocket API}, anch'essa presente nell'HTML Living Standard di WHATWG.
Il flusso di comunicazione basato su WebSocket può essere espresso come segue\cite{websockets} ed illustrato in figura \ref{fig:websockets}:
\begin{enumerate}
  \item Il client tramite la chiamata API \lstinline{new WebSocket('/api/myEndpoint')} apre una nuova connessione HTTP, specificando nella richiesta gli header \lstinline{Upgrade: WebSocket} e \lstinline{Connection: Upgrade}.
  \item Il client registra le callback agli eventi \lstinline{onmessage}, \lstinline{onopen}, \lstinline{onclose} e \lstinline{onerror}.
  \item Il server risponde alla richiesta con codice \lstinline{101 Switching Protocols} e gestisce il socket aperto tramite protocollo WebSocket.
  \item Il client e il server possono finalmente scambiarsi messaggi in entrambe le direzioni.
\end{enumerate}
L'implementazione è molto simile a quella dei Server Sent Events:
\lstinputlisting[caption=Client side WebSocket example]{snippets/websocket_sample.js}

\begin{figure}[!htbp]
\centering
\includegraphics[width=.5\textwidth]{assets/websockets.png}
\caption{WebSockets Flow}
\label{fig:websockets}
\end{figure}
I WebSocket sono supportati da tutti i browser moderni. 
Sfortunatamente al momento della stesura non è possibile comunicare con i WebSocket tramite HTTP/2, in quanto non dispone del meccanismo di Upgrade di HTTP/1.1. Tuttavia i browser si stanno adoperando per supportare l'apertura di una comunicazione attraverso WebSocket su HTTP/2 seguendo il recente RCF 8441\cite{websockets_http2_rfc}. Ciò porterà a poter sfruttare il multiplexing offerto da HTTP/2 automaticamente anche con i WebSocket.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
							% ListenJS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{ListenJS}
Il mio contributo nell'ambito dello sviluppo di web application real-time si concretizza in \textit{ListenJS}, un insieme di librerie che permette di osservare in tempo reale gli aggiornamenti ad una o più risorse.
Il progetto comprende anche un'applicazione di esempio che permette a più utenti di collaborare all'inserimento, la modifica e la cancellazione di appuntamenti su un calendario tramite una web app.

\bigskip

Le librerie messe a disposizione sono rispettivamente \lstinline{listenjs} e \lstinline{listenjs-server}, la prima è una libreria client, utilizzabile su qualsiasi browser che supporti i WebSocket, la seconda è una libreria server utilizzabile su server sviluppati in NodeJS.
Entrambe le librerie sono volutamente framework-agnostic, cioè possono essere facilmente integrate in qualsiasi framework già esistente, sia front-end (e.g. Angular, React, VueJS...) che back-end (e.g. Express, Fastify, Koa...), e non sono opinionate rispetto ad alcun paradigma di programmazione. Utilizzando costrutti già presenti in Javascript, e non avendo dipendenze ad altre librerie, possono essere integrate in una codebase già esistente apportando pochissime modifiche.

\bigskip

ListenJS è volta a diminuire l'inerzia dell'implementazione di un'app real-time basata su WebSocket facilitandone l'utilizzo e riducendo il codice boilerplate. Inoltre fornisce una serie di funzionalità descritte nella sezione \ref{sec_features} per migliorare la gestione delle risorse, l'affidabilità e la semplicità d'utilizzo.

\bigskip

%%%%%%%%%%%%%%%%%%%%%%%%%
			% Struttura ad alto livello
%%%%%%%%%%%%%%%%%%%%%%%%%
%\section{Struttura ad alto livello}\label{sec_struttura_alto_livello}
Le librerie utilizzano i WebSocket come layer di trasporto e astraggono la comunicazione scambiandosi dei messaggi predefiniti, ma che contengono payload definiti dall'utente.
La scelta di utilizzare i WebSocket come trasporto invece dei Server Sent Events è dovuta ai seguenti motivi:
\begin{enumerate}
\item I WebSocket sono supportati da tutti i browser moderni, a differenza dei Server Sent Events che (al momento della stesura) non sono supportati da Internet Explorer e alcune versioni di Edge.
\item Con i Server Sent Events non è possibile fare multiplexing utilizzando HTTP/1.1, in quanto non è possibile inviare messaggi successivi da client a server utilizzando la stessa connessione.
\item Poiché con i Server Sent Events non si possono inviare messaggi da client a server sulla stessa connessione, risulta difficile implementare meccanismi di ping personalizzati. È dunque complicato lato client verificare quando un server non è più raggiungibile.
\end{enumerate}
Il client può mettersi in ascolto di una o più risorse in qualsiasi istante nel tempo, e ricevere aggiornamenti in tempo reale delle risorse osservate, come in figura \ref{fig:listenjs}.
\begin{figure}[!htbp]
\centering
\includegraphics[width=.7\textwidth]{assets/listenjs.png}
\caption{ListenJS client-server interaction}
\label{fig:listenjs}
\end{figure}

\section{Libreria client}
La libreria client permette con una linea di codice di rimanere in ascolto di qualsiasi risorsa negli endpoint che si desidera.

\subsection{Installazione}
La libreria client di ListenJS può essere aggiunta ad un progetto che sfrutti un module bundler (come per esempio WebPack) tramite il package manager NPM, eseguendo il comando:
\begin{center}
\lstinline{npm install @filippovigani/listenjs}
\end{center}
per poi essere importata o tramite CommonJS o gli import dei moduli di ES6:
\begin{center}
\lstinline{const listen = require('@filippovigani/listenjs').listen}
\end{center}
oppure
\begin{center}
\lstinline|import { listen, ... } from "@filippovigani/listenjs/listen"|
\end{center}  
Alternativamente è possibile scaricare direttamente il codice sorgente\cite{listenjs_repo} e importarlo nel progetto che si desidera.

\subsection{Utilizzo}
Per ogni risorsa per cui si vuole essere notificati degli aggiornamenti, basterà semplicemente chiamare la funzione per ascoltare uno specifico endpoint:
\lstinputlisting[caption=ListenJS client example]{snippets/listenjsclient_sample.js}
L'URI passato come argomento della funzione, può sia essere relativo, e quindi utilizzare lo stesso dominio della pagina di origine, oppure specificare un indirizzo completo, per esempio \lstinline{differentDomain.com/api/appointments}. Questo dominio per permettere al protocollo di WebSocket di fare l'handshake, dovrà avere abilitato i CORS (Cross-Origin Resource Sharing) in quanto la risorsa è su un'origine differente.

\section{Libreria server}
La libreria server permette di inizializzare un server che supporti i WebSocket e gestisca i client in ascolto sulle varie risorse, permettendo di notificare tutti i client in ascolto su una specifica risorsa. 
\subsection{Installazione}
Per aggiungere la libreria server di ListenJS ad un progetto NodeJS è sufficiente eseguire il comando:
\begin{center}
\lstinline{npm install @filippovigani/listenjs-server}
\end{center}
e per poterla utilizzare basta importarla come tutti i moduli di NodeJS
\begin{center}
\lstinline{const listen = require('@filippovigani/listenjs-server')}
\end{center}
Come per la parte client, è in alternativa possibile scaricare il codice sorgente\cite{listenjs_server_repo} e importarlo manualmente nel progetto.

\subsection{Utilizzo}
In fase di inizializzazione del server è necessario fare il binding di un server HTTP di NodeJS già esistente con ListenJS, per poter inizializzare connessioni tramite WebSocket. Ciò si può fare chiamando la funzione \lstinline{setup} come segue: 
\lstinputlisting[caption=ListenJS server setup example]{snippets/listenjsserver_sample.js}
In caso fossero utilizzati framework per il routing degli endpoint, è sempre possibile reperire l'istanza del server HTTP sottostante per poter inizializzare ListenJS. Per esempio, utilizzando Fastify, ListenJS verrà inizializzato in questo modo:
\lstinputlisting[caption=ListenJS Fastify setup example]{snippets/listenjsserver_fastify_sample.js}
Per qualsiasi altro framework si può trovare nella documentazione come reperire il server HTTP.

\bigskip

Una volta inizializzato, è possibile notificare i client che sono in ascolto di una risorsa tramite la funzione \lstinline{notify}. Per esempio, in un endpoint POST, il codice per notificare tutti i client in ascolto su una risorsa è il seguente:
\lstinputlisting[caption=ListenJS server notify example]{snippets/listenjsserver_notify_sample.js}

La libreria si occuperà di inviare un messaggio contentente il nuovo payload a tutti e soli i client in ascolto. Se non ci fosse nessun client in ascolto su quella specifica risorsa, la chiamata non avrà alcun effetto.

%%%%%%%%%%%%%%%%%%%%%%%%%
			% Features
%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Features}\label{sec_features}
Oltre a semplificare la comunicazione dell'aggiornamento delle varie risorse in ascolto dai client, ListenJS implementa una serie di funzionalità per semplificare la vita allo sviluppatore, e permettere di adempire al Single Responsibility Principle\cite{single_responsibility_principle} nell'applicazione real-time che utilizza questo sistema di comunicazione.
\subsection{Disconnection detection}
L'evento \lstinline{onclose} fornito dai WebSocket viene lanciato solo nel caso in cui il socket venga chiuso esplicitamente o dal client o dal server tramite l'handshake di chiusura specificato nell'RFC 6455. Tuttavia, in caso di problemi di network, la chiusura del socket non verrà notificata, né dal client né dal server. In aggiunta, i messaggi scambiati in caso di pessime condizioni di network verranno lasciati in sospeso.

\bigskip

Per ovviare a questo problema ListenJS implementa un sistema di heartbeat (aka ping-pong), che fa sì che il client invii periodicamente dei messaggi di ping, aspettandosi un messaggio di pong dal server entro un certo timeout. Se non dovesse riceverlo, allora considererà il socket come chiuso, provando ad iniziare l'handshake di chiusura tramite la chiamata alla WebSocket API. Di contro, il server si aspetterà di ricevere un messaggio di ping ogni intervallo prestabilito. Se non dovesse succedere, allora si aspetterà di non avere più connettività con il client, chiudendo il socket.
\subsection{Reconnection}
I WebSocket non permettono di riaprire un socket precedentemente chiuso. Ciò comporta che in caso di disconnessione dovuta a delle condizioni di network non ottimali, non sia possibile riutilizzare lo stesso socket per mantenere la sessione precedente attiva.

\bigskip

ListenJS fornisce un sistema di riconnessione aprendo un nuovo WebSocket, ma mantenendo le informazioni di uno specifico client come se la sessione precedente fosse stata ripristinata. Conseguentemente il client non dovrà preoccuparsi di rimettersi in ascolto delle risorse precedentemente specificate, ma sarà tutto gestito dalla libreria.

\subsection{Multiplexing}\label{multiplexing}
Un'implementazione naïve per rimanere in ascolto di alcune risorse potrebbe essere quella di aprire un WebSocket per ogni risorsa che si vuole osservare, specificando l'URL della risorsa nel pacchetto di handshake. Per esempio, se volessimo rimanere in ascolto di due risorse \lstinline{foo} e \lstinline{bar}, potremmo aprire due WebSocket chiamando \lstinline{new WebSocket('ws://myDomain.com/api/foo')} e \lstinline{new WebSocket('ws://myDomain.com/api/bar')}. Tuttavia così facendo si aprirebbero due connessioni separate, che non è ideale per due motivazioni:
\begin{itemize}
\item I browser limitano il numero di connessioni HTTP contemporanee su uno stesso dominio\cite{http11_rfc}. La maggior parte dei browser moderni consentono un massimo di sei connessioni per dominio.
\item Per aprire un WebSocket c'è un ritardo dovuto all'handshake specificato dal protocollo, che potrebbe essere evitato utilizzando lo stesso socket.
\end{itemize}

\bigskip

Per evitare questi problemi, ListenJS sfrutta intelligentemente le connessioni attive. Dunque, se non esiste un socket aperto per uno specifico dominio, allora ne aprirà uno, altrimenti riutilizzerà lo stesso socket per scambiare ulteriori messaggi. Per fare un parallelismo con l'esempio precedente, se con la libreria client si decidesse di osservare prima \lstinline{foo} e poi \lstinline{bar} sullo stesso dominio, prima verrebbe aperto un socket per il dominio, mentre successivamente verrebbe riutilizzato il socket già aperto per comunicare l'intenzione di mettersi in ascolto su \lstinline{bar}.
In aggiunta, se nel ciclo di vita dell'applicazione non ci fosse più nessuna risorsa osservata su uno stesso dominio, ListenJS si occuperà di chiudere il socket per liberare le risorse utilizzate.

%%%%%%%%%%%%%%%%%%%%%%%%%
			% ListenJS: Dettagli implementativi
%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{ListenJS: Dettagli implementativi}
Abbiamo visto ad alto livello cosa offre ListenJS e in generale come queste funzionalità sono utili nello sviluppo di applicazioni real-time. Possiamo ora andare più a fondo nel funzionamento specifico, in modo da avere le basi per estendere e potenzialmente migliorare questi comportamenti.

\section{Message channel}
Il funzionamento del sistema si basa sullo scambio dei messaggi che hanno una struttura ben specifica, e conosciuta sia dal client che dal server. Ogni messaggio può essere un \textit{Control Message} o un \textit{Payload Message}, e sono dei messaggi testuali codificati in UTF-8 e serializzati in JSON come segue:
\lstinputlisting[caption=ListenJS Message Contract]{snippets/listenjs_message.json}
In aggiunta contengono altri valori specifici di una certa azione. In particolare l'azione \lstinline{<ACTION>} è una stringa che specifica il tipo di messaggio di controllo (o di payload), e può assumere i seguenti valori:
\begin{itemize}
\item Da client a server:
  \begin{itemize}
  \item \lstinline{HANDSHAKE}: Specifica un messaggio di controllo per inizializzare un nuova nuova connessione con un client. Facoltativamente può essere specificato un \lstinline{clientId} come campo extra per ripristinare una sessione di uno specifico client. Se il server non riceve nessun messaggio di handshake entro un timeout specificato (default: 10000 ms) da quando un socket viene aperto, chiude automaticamente la connessione.
  \item \lstinline{SUBSCRIBE}: Specifica che il client desidera mettersi in ascolto dell'endpoint specificato con il campo \lstinline{path}, tramite un observer gestito dal client con \lstinline{observerId}.
  \item \lstinline{UNSUBSCRIBE}: Specifica che il client non desidera più ricevere notifiche di aggiornamenti dell'endpoint specificato con il campo \lstinline{path}.
  \item \lstinline{HEARTBEAT}: Invia un messaggio di ping al server per verificare che sia ancora raggiungibile.
  \end{itemize}
\item Da server a client:
  \begin{itemize}
  \item \lstinline{HANDSHAKE_ACK}: Risponde ad un messaggio di handshake, chiudendo la procedura di riconoscimento del client. Se un \lstinline{clientId} è specificato come campo, allora verrà ripristinato quel client, recuperando le informazioni sulle risorse che sta ascoltando. Altrimenti, genererà un \lstinline{clientId} univoco come UUID (e.g. \lstinline{B16B00B5-81F6-A420-81F6-008C3285ADB9}).
  \item \lstinline{SUBSCRIBE_ACK}: Conferma al client che la sottoscrizione alla risorsa in ascolto da \lstinline{observerId} è avvenuta con successo.
  \item \lstinline{UNSUBSCRIBE_ACK}: Conferma al client l'avvenuta rimozione delle sottoscrizioni alla risorsa specificata dal suo \lstinline{path}.
  \item \lstinline{HEARTBEAT_ACK}: Invia un messaggio di pong al client in risposta ad un ping.
  \item \lstinline{UPDATE}: Invia un messaggio di payload al client, specificandone il contenuto nel campo \lstinline{body} e la risorsa di riferimento nel campo \lstinline{path}.
  \end{itemize}
\end{itemize}

\section{Observer pattern across the stack}
La Gang of Four definisce l'observer pattern\cite{observer} come un behavioral pattern che prevede che un certo numero di observer siano notificati quando un subject subisce un cambiamento di stato. Questo tipo di pattern è largamente utilizzato nel design di interfacce grafiche, dove si vuole ridurre al minimo il coupling tra le classi per non renderle meno riutilizzabili. Questo però non significa che non possa essere utilizzato in ambiti al di fuori dello sviluppo di UI.

\bigskip

Nel nostro caso, l'observer pattern viene inteso come publish/subscribe, e funziona attraverso i differenti layer di comunicazione. Ciò significa che viene in primo luogo applicato ad un livello di astrazione più alto, dove gli observer sono i vari client, e il subject è il server.

Inoltre, lo stesso pattern viene applicato nella gestione del client, dove si hanno diversi observer che stanno in ascolto di una specifica risorsa. Quando un messaggio di payload viene ricevuto da un \textit{manager} del client, questo viene inoltrato agli observer corretti che sono in ascolto su una risorsa.

In ListenJS il manager è un'istanza che gestisce la connessione ad uno specifico dominio. Ogni manager tiene in memoria una lista di observer. Quando si effettua la chiamata \lstinline{listen(path)}, viene creato un nuovo observer per il path specificato, ed aggiunto al manager.

Un observer è descritto dalle seguenti proprietà:
\begin{itemize}
\item \lstinline{id}: Identifica l'observer univocamente con uno UUID
\item \lstinline{path}: Indica il path che l'observer desidera osservare
\item \lstinline{status}: Indica lo stato dell'observer, che può essere:
  \begin{itemize}
  \item \lstinline{WAITING_HANDSHAKE}: L'observer è stato appena inizializzato e sta attendendo che un handshake sia completato per potersi sottoscrivere
  \item \lstinline{SUBSCRIBING}: Il manager ha inviato la richiesta di osservare l'endpoint, ma sta attendendo di ricevere una conferma
  \item \lstinline{UNSUBSCRIBING}: Il manager ha inviato la richiesta di non osservare più l'endpoint
  \item \lstinline{LISTENING}: L'observer sta correttamente ascoltando gli aggiornamenti ad una risorsa
  \item \lstinline{ERROR}: È avvenuto un errore imprevisto
  \end{itemize}
\end{itemize}

I passaggi di stato da uno all'altro rispetto agli eventi che hanno luogo nel manager sono descritti in figura \ref{fig:observer_statuses}.

\begin{figure}[htbp]
\centering
\includegraphics[width=.9\textwidth]{assets/observer_statuses.png}
\caption{ListenJS client observer statuses}
\label{fig:observer_statuses}
\end{figure}

Come l'observer, anche il manager mantiene uno stato interno che indica la fase della connessione. Lo stato del manager è legato agli eventi ricevuti dal socket, ma è più preciso sulla fase di connessione:
\begin{itemize}
\item \lstinline{IDLE}: Manager appena inizializzato
\item \lstinline{CONNECTING}: Il socket è in fase di connessione
\item \lstinline{HANDSHAKING}: Il socket è connesso ma il manager non ha ancora finito la fase di handshake
\item \lstinline{CONNECTED}: Il socket è connesso e l'handshake è stato eseguito correttamente
\item \lstinline{DISCONNECTED}: Il socket è disconnesso
\item \lstinline{RECONNECTING}: Il socket è in fase di connessione dopo che un altro socket è stato chiuso
\item \lstinline{ERROR}: È avvenuto un errore imprevisto
\end{itemize}

I cambiamenti di stato in base agli eventi del socket e il numero di observer sono meglio rappresentati in figura \ref{fig:manager_statuses}.

\begin{figure}[htbp]
\centering
\includegraphics[width=.9\textwidth]{assets/manager_statuses.png}
\caption{ListenJS client manager statuses}
\label{fig:manager_statuses}
\end{figure}

Il manager gestisce sia gli observer, che il socket. 
In particolare, quando un nuovo observer viene aggiunto al manager, esso utilizza il proprio stato interno per capire quando sia opportuno inviare i messaggi di controllo. Per esempio, se viene aggiunto un nuovo observer, ma lo stato del manager è \lstinline{CONNECTING} o \lstinline{HANDSHAKING}, allora dovrà mettersi in attesa che il proprio stato sia propriamente \lstinline{CONNECTED}. Una volta \lstinline{CONNECTED} (o nel caso lo fosse già in fase di aggiunta), potrà procedere ad inviare tramite il socket i messaggi di controllo per fare il \lstinline{SUBSCRIBE} del \lstinline{path} specificato.
Inoltre, il manager si occupa di aprire un nuovo socket appena un nuovo observer viene aggiunto. Quando invece vengono rimossi tutti gli observer per lo stesso manager, allora si occuperà di chiudere il socket attuale.

\section{Implementazione features}

Nella sezione precedente è stato definito formalmente il canale di comunicazione tra libreria client e libreria server, e l'interazione tra i componenti principali. Per quanto riguarda i dettagli implementativi specifici dell'una o dell'altra, vale la pena analizzare singolarmente come le feature siano state implementate.

\subsection{Multiplexing}

Ogni richiesta che viene fatta per mettersi in ascolto di una risorsa, deve essere gestita da un manager. Un manager però, come abbiamo visto, gestisce solo un socket alla volta. Il componente software che si occupa di gestire i manager è stato chiamato \textit{multiplexer}.

\bigskip

Il multiplexer si occupa di assicurarsi che per ogni richiesta effettuata, ci sia sempre solamente un manager attivo per ogni dominio di destinazione. Il funzionamento è piuttosto intuitivo: ogni richiesta del client di ascoltare una risorsa passa attraverso il client, che fa da proxy per quella richiesta, inoltrandola al manager corretto. Il flusso per questa gestione può essere riassunto come segue:
\begin{enumerate}
\item Il client invia una richiesta al multiplexer
\item Il multiplexer fa il parsing dell'URL di destinazione, estraendo il dominio del server che si vuole ascoltare
\item Il multiplexer a questo punto controlla se nella propria map di manager, indicizzati per dominio di destinazione, è presente un manager
\item Se esiste già un manager per quel dominio, inoltra la richiesta. Altrimenti, crea un nuovo manager, lo salva nella map, e inoltra la richiesta
\end{enumerate}

Oltre a gestire i manager per limitare i socket ad uno per dominio, il multiplexer si occupa anche di fare routing degli eventi scatenati dai diversi manager. In tal modo chi utilizza la libreria può rimanere in ascolto di eventi di connessione e disconnessione in un unico punto, nascondendo così i dettagli implementativi dello smistamento dei socket.

\subsection{Disconnection detection}

L'implementazione browser dei WebSocket non prevede nessun meccanismo di rilevazione di disconnessione, a meno che il socket non venga chiuso esplicitamente da una delle due parti con un handshake di chiusura completo. Per ovviare a questo problema, è stato sviluppato un meccanismo di keep alive implementato un livello sopra ai WebSocket.

\bigskip

Ogni manager in fase di handshake di ListenJS, da non confondere con l'handshake dei WebSocket, può inviare due parametri di configurazione: \lstinline{pingInterval} e \lstinline{pingTimeout}, espressi in millisecondi. Il server che riceve una richiesta di handshake può onorare i due parametri in arrivo, se presenti, e rispondere con gli stessi parametri, o rispondere con dei parametri diversi. Il client, una volta finito l'handshake, fa fede ai parametri ricevuti in risposta nell'ACK di handshake. Questo sistema è stato pensato in caso sia necessario limitare il carico di messaggi in arrivo sul server.

Una volta terminato l'handshake, entrambe le parti hanno un contract sul quale fare affidamento per stabilire se una o l'altra parte è ancora connessa.
Da un lato, il client invierà periodicamente un pacchetto di ping al server, con intervallo \lstinline{pingInterval}, aspettandosi dal server una risposta (pong) entro \lstinline{pingTimeout} millisecondi, o considerando il socket disconnesso dopo quel periodo di timeout.
Dall'altro lato, il server si aspetterà di ricevere un messaggio di ping ogni \lstinline{pingInterval} millisecondi, per rispondere con un pong. Se da un ping all'altro dovesse passare più tempo di \lstinline{pingInterval + pingTimeout}, considererà il socket come disconnesso. In questo caso il \lstinline{pingTimeout} è aggiunto per consentire un tempo massimo di ricezione dell'intervallo di ping.

\subsection{Reconnection}
Una volta che un socket viene chiuso, o si rileva una disconnessione con il sistema descritto in precedenza, il manager si occupa di riaprire un nuovo socket. Se dovesse fallire nel riaprire un socket, allora attenderà un certo periodo di tempo, e ritenterà. La frequenza con la quale un manager prova a riaprire un socket è scandita da un algoritmo chiamato \textit{Truncated Exponential Backoff}.

\begin{align*}
  E(x) &= min(d * f^x * (1 + j * r), t)
\end{align*}

La funzione calcola il prossimo delay da aspettare prima di effettuare un nuovo tentativo, sulla base del numero di tentativi $x$ e di una base esponenziale $f$. $d$ è un delay minimo, $t$ è una soglia massima, $r$ è un fattore random generato ad ogni esecuzione che nel range $[-1, 1]$, e $j$ è una durata di jitter, per non ripetere diverse richieste nello stesso istante continuativamente.

ListenJS usa $f=2$, $j=0.5$, mentre i valore di minimo e di massimo possono essere configurati.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
							% Valutazione
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Valutazione}
L'obiettivo del progetto era quello di sviluppare due librerie che fossero semplici da utilizzare e che facessero uso di tecniche e tecnologie avanzate come i WebSocket per migliorare l'esperienza su tutti i fronti: dallo end-user al programmatore front-end al programmatore back-end.

\bigskip

Per meglio valutare l'applicabilità della soluzione, oltre alle librerie client e server, è stata sviluppata un'applicazione di esempio che ne facesse uso. Questa applicazione è un'istanza specifica di un caso d'uso particolare, ma è un buon punto di partenza per dimostrare la funzionalità della soluzione proposta.

%%%%%%%%%%%%%%%%%%%%%%%%%
      % Applicazione di esempio
%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Applicazione di esempio}\label{sec_applicazioneesempio}
L'applicazione di esempio sviluppata permette a diversi utenti di contribuire alla gestione degli appuntamenti in real-time. Tutti gli utenti che utilizzano l'applicazione collaborano all'aggiunta, modifica e cancellazione di appuntamenti su un calendario condiviso, e vedono le modifiche effettuate dagli altri utenti in tempo reale. In aggiunta, è possibile spostarsi di periodo e visualizzare il calendario in formato giorno, settimana e mese, per avere diversi gradi di granularità.

\begin{figure}[htbp]
\centering
\includegraphics[width=1\textwidth]{assets/listenjs_sample_app.png}
\caption{ListenJS sample app interface}
\label{fig:listenjs_sample_app}
\end{figure}

\begin{figure}[htbp]
\centering
\includegraphics[width=1\textwidth]{assets/listenjs_sample_app_edit.png}
\caption{ListenJS sample app interface - add/edit appointment}
\label{fig:listenjs_sample_app_edit}
\end{figure}

L'applicazione client\cite{listenjs_sample_repo} è stata sviluppata in React\cite{react}, libreria front-end che favorisce lo sviluppo con un paradigma di programmazione reactive. Nello sviluppo web la programmazione reattiva sta prendendo sempre più piede perché rende il codice di più semplice comprensione e favorisce un'interazione basata su eventi\cite{reactive_programming}, che nel nostro caso semplifica la gestione degli aggiornamenti alle risorse che possono avvenire in un qualsiase istante.

È stato osservato che utilizzare React semplifica di molto la gestione degli aggiornamenti alle risorse, poiché mantenendo uno stato condiviso e costruendo la UI sulla base dello stato osservato, ogni volta che si riceve un aggiornamento alla risorsa basterà modificare lo stato e il framework si occuperà di apportare le modifiche necessare alla UI. Per mostrare la concisione che si può ottenere, di seguito è riportato il codice richiesto per integrare gli aggiornamenti periodici alle risorse nel front-end:
\lstinputlisting[caption=ListenJS sample app resource listening]{snippets/listenjs_sample_listen.js}
Sebbene ListenJS sia stato pensato in modo da essere framework-agnostic, la logica basata su observer sulla quale è stato costruito si sposa molto bene con librerie quali RxJS - libreria che si sta facendo strada anche sul web visto il successo delle suo controparti RxJava, RxSwift, eccetera.

\bigskip

L'indipendenza da framework è stata osservata anche nella parte del back-end, sviluppato in NodeJS\cite{nodejs} utilizzando Fastify\cite{fastify} come framework. L'integrazione con Fastify è stata semplice ed ha permesso di modificare gli oggetti di response del framework tramite degli hook per semplificare ulteriormente la notifica ai client in ascolto su una risorsa.
\lstinputlisting[caption=ListenJS sample app Fastify hook]{snippets/listenjs_sample_server_hook.js}

L'applicazione è stata configurata con Webpack\cite{webpack} e distribuita su due domini diversi per verificare l'impatto con i CORS: la parte client è stata transpilata per poi essere servita su un sito statico in Apache, mentre la parte server è stata servita mediante un container Docker. Come volevasi dimostrare, per poter sì che l'handshake dei WebSocket funzionasse (così come tutte le altre richieste REST), la parte in NodeJS richiede di avere abilitato i CORS avendo come origine l'altro server da dove veniva servito il client.

\bigskip

Ultima ma non meno importante, è stata valutata la user experience nell'utilizzo dell'applicazione. Semplificare l'utilizzo dei WebSocket con librerie come ListenJS porta a migliorare le performance e a rendere scelte di design più semplici da implementare: si pensi al classico pulsante di refresh, reso futile se un'applicazione implementa un sistema reactive basato sugli observer e su WebSocket. In definitiva, migliorare le performance e l'esperienza utente porta ad aumentare il conversion rate\cite{why_performance_matters} e dunque ad aumentare i guadagni, con spese di sviluppo pressoché nulle.

%%%%%%%%%%%%%%%%%%%%%%%%%
			% Confronto tra XHR polling e WebSocket
%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Confronto tra XHR polling e WebSocket}\label{sec_confrontopollingwebsockets}

Una prima valutazione sull'efficacia del progetto va fatta confrontando le performance tra il polling e i WebSocket, in quanto sebbene ListenJS non sia l'alternativa unica al polling, grazie alle funzionalità che offre rende più seamless il passaggio da polling a WebSocket come tecnica di aggiornamento delle risorse.

\subsection{Latenza}
Per quanto riguarda i tempi di risposta medi, sono già stati fatti dei test empirici confrontando polling, long polling e WebSocket\cite{communicating_websocket}. I risultati mostrano che in ogni caso, i WebSocket hanno tempi medi di risposta inferiori rispetto al polling. Per quanto riguarda il long polling, i tempi di risposta sono comparabili con quelli dei WebSocket, ad eccezione dei casi in cui ci sia backpressure\cite{backpressure} sul server: in quel caso i messaggi che il server dovrà inviare al client saranno ritardati dai tempi di apertura di una nuova connessione, in quanto ogni nuovo messaggio da inviare dovrà rimanere in attesa della prossima richiesta di long polling, e i nuovi messaggi in arrivo durante questo tempo di attesa verranno messi in coda, aumentando progressivamente la latenza. La figura \ref{fig:latency} illustra chiaramente questo comportamento, mentre la figura \ref{fig:latency_chart} mette a confronto i risultati ottenuti.

\begin{figure}[htbp]
\centering
\includegraphics[width=0.9\textwidth]{assets/latency.png}
\caption{Polling, long polling and WebSocket latency comparison}
\label{fig:latency}
\end{figure}

\begin{figure}[htbp]
\centering
\includegraphics[width=0.9\textwidth]{assets/latency_chart.png}
\caption{Polling, long polling and WebSocket latency results}
\label{fig:latency_chart}
\end{figure}

\subsection{Traffico dati}

Per quanto riguarda l'utilizzo della banda, i dettagli del consumo dipendono dalle circostanze. Una richiesta di polling HTTP, deve stabilire una connessione TCP e confermare tale connessione, scambiandosi un certa quantità di dati, ancora di più se si tratta di una connessione SSL. Successivamente deve inviare la richiesta HTTP, includendo eventuali cookie, headers e URL della GET. Poi il server deve rispondere, e la maggior parte delle volte questo scambio di informatzioni è interamente sprecato perché non c'è nulla da notificare.

\bigskip

Supponiamo di avere un'applicazione web che utilizzi il polling come metodo di aggiornamento dei dati. Per ogni richiesta di polling, gli header scambiati potrebbero essere come i seguenti:
\lstinputlisting[caption=HTTP Request and response headers example]{snippets/example_headers.txt}
Il totale tra la richiesta e la risposta corrisponde a 568 byte. In base alle diverse casistiche, questo valore potrebbe essere leggermente inferiore o discretamente superiore; non è fuori dal comune vedere richieste da 1500 o più byte.
Vediamo ora 3 casi d'uso differenti in base al numero di client che fanno polling contemporanemnte:
\begin{enumerate}
\item \textbf{Use case A}: $1000$ client fanno polling ogni secondo: Il throughput della rete è $568 \times 1000 = 568000$ byte al secondo $=> 4.5$ Mbps
\item \textbf{Use case B}: $10000$ client fanno polling ogni secondo: Il throughput della rete è $568 \times 10000 = 5680000$ byte al secondo $=> 45.4$ Mbps
\item \textbf{Use case C}: $100000$ client fanno polling ogni secondo: Il throughput della rete è $568 \times 100000 = 56800000$ byte al secondo $=> 454.4$ Mbps
\end{enumerate}

Per avere una stima più bassa possibile (a favore del polling), supponiamo che i dati in risposta alla richiesta di polling vengano inviati solo se il client non ha il dato aggiornato - e conseguentemente il server gestisca una sorta di versionamento della risorsa osservata. Inoltre, supponiamo che la risorsa venga aggiornata ogni 5 secondi ed abbia un payload di dimensione 100 byte. Significa che nel caso del polling dobbiamo aggiungere questa dimensione di payload:
\begin{enumerate}
\item \textbf{Use case A}: $1000$ client aprono una nuova connessione ogni $5$ secondi. Il throughput è di $568 \times 1000 / 5 = 113600$ byte al secondo $=> 0.9$ Mbps
\item \textbf{Use case A}: $10000$ client aprono una nuova connessione ogni $5$ secondi. Il throughput è di $568 \times 10000 / 5 = 1136000$ byte al secondo $=> 9.1$ Mbps
\item \textbf{Use case A}: $100000$ client aprono una nuova connessione ogni $5$ secondi. Il throughput è di $568 \times 100000 / 5 = 11360000$ byte al secondo $=> 90.9$ Mbps
\end{enumerate}

Nel caso del long polling, si dovrà aprire una nuova connessione per ogni volta che un nuovo dato è ricevuto. Il traffico dati è dato dunque da:
\begin{enumerate}
\item \textbf{Use case A}: $1000$ client ricevono $100$ byte ogni $5$ secondi. Il throughput è di $100 \times 1000 / 5 = 20000$ byte al secondo $=> 1.6$ Mbps
\item \textbf{Use case B}: $10000$ client ricevono $100$ byte ogni $5$ secondi. Il throughput è di $100 \times 10000 / 5 = 200000$ byte al secondo $=> 16$ Mbps
\item \textbf{Use case C}: $100000$ client ricevono $100$ byte ogni $5$ secondi. Il throughput è di $100 \times 100000 / 5 = 2000000$ byte al secondo $=> 160$ Mbps
\end{enumerate}

Possiamo ora andare a confrontare il traffico di data confrontando il caso del polling e long polling, che scambieranno i byte degli header e i byte del payload, con i WebSocket, che invece riceverà solo i byte del payload, oltre ai byte per la prima connessione che a regime sono trascurabili\cite{websocket_performance}. L'andamento è chiaramente visibile in figura \ref{fig:bandwidth}

\begin{figure}[htbp]
\centering
\includegraphics[width=0.9\textwidth]{assets/bandwidth.png}
\caption{Polling, long polling and WebSocket bandwidth usage comparison}
\label{fig:bandwidth}
\end{figure}

Dal grafico si nota chiaramente che con l'aumentare del numero di client, il consumo di traffico di banda nel caso del polling aumenti esponenzialmente molto più rapidamente dei WebSocket, il che rende l'utilizzo del polling una soluzione non facilmente scalabile.

\subsection{User experience}
Entrambi gli aspetti di performance visti in precedenza sono strettamente collegati tra di loro, e hanno un effetto anche sull'esperienza dell'utente che utilizza l'applicazione. Aumentando la frequenza di polling, si ha una ridotta latenza rispetto all'istante in cui una risorsa viene aggiornata, ma aumenterà il consumo di banda, che talvolta per applicazioni web utilizzate da smartphone potrebbe portare a un consumo di traffico dati non desiderabile. Viceversa, riducendo la frequenza di polling, si riduce il consumo di banda ma si riceveranno dati con un ritardo che potenzialmente potrebbe non essere accettabile. Con il polling sta al programmatore pesare questo tradeoff tra ritardo e consumo dati.

Facendo uso dei WebSocket questa difficoltà di stabilire un equilibrio tra le due dimensioni viene rimossa, in quanto si ottiene il meglio da entrambi i lati. Conseguentemente, la user experience dell'utente è migliorata sia nei tempi di risposta, che nel consumo della banda.

%%%%%%%%%%%%%%%%%%%%%%%%%
			% Valore aggiunto di ListenJS
%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Valore aggiunto di ListenJS}\label{sec_valorelistenjs}

Nella sezione precedente abbiamo fatto una valutazione quantitativa rispetto ai miglioramenti ottenuti tramite l'utilizzo dei WebSocket. Tuttavia tali benefici sono effettivamente fruibili solo se per lo sviluppatore che crea un'applicazione web il guadagno risulta inferiore al costo di implementazione.

\subsection{Immediatezza integrazione}
Utilizzare un sistema basato sui WebSocket come ListenJS semplifica l'utilizzo di WebSocket astrando i dettagli implementativi dell'API esposta dai browser. Avendo due librerie simmetriche lato browser e lato server che comunicano tra di loro senza necessità di configurazione permette di essere più veloci nell'integrazione dei WebSocket: Nei casi più banali nel front-end sarà sufficiente mettere una chiamata alla funzione per ascoltare le modifiche di una risorsa alla prima chiamata REST di ogni differente risorsa, e nel back-end chiamare la funzione di notifica dei client quando viene chiamato l'endpoint PUT o POST corrispondente.

\bigskip

Avere la possibilità di ottenere un comportamento server-push in maniera così semplice rende l'utilizzo dei WebSocket più immediato, il che porta a tutti i benefici descritti in precedenza con un costo implementativo molto basso.

\subsection{Utilizzo risorse e limitazioni browser}
Impostare un approccio basato sui WebSocket coinvolge una serie di casi da gestire che non sono immediati. ListenJS permette allo sviluppatore che usa la libreria di non doversi preoccupare di gestire funzionalità di difficile implementazione come disconnection detection, reconnection e multiplexing, talvolta indispensabili: si pensi al limite dei socket aperti contemporaneamente descritto nella sezione \ref{multiplexing}. Anche questo dovrebbe portare a rendere più lineare l'utilizzo dei WebSocket, non dovendo andare a gestire funzionalità che tendenzialmente hanno minore priorità: è già gestito dalla libreria.

\subsection{Architettura}
In ultimo utilizzare ListenJS come libreria per osservare le risorse definisce una chiara \textit{Separation Of Concerns}, in quanto sarà la libreria ad occuparsi esclusivamente del sistema di comunicazione e notifica delle risorse. Lo sviluppatore che crea un'applicazione web real-time con ListenJS non deve preoccuparsi di non mischiare la logica dell'applicazione con la logica della gestione dei socket. Si dice in questo caso che la libreria crea una \textit{boundary} tra il sistema di comunicazione e la logica dell'applicazione: una linea di separazione che non permette di creare dipendenze forti tra i dettagli implementativi del canale di comunicazione e gli altri livelli più alti (e.g. domain e presentation) dell'applicazione.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
						% Conclusioni
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\clearpage{\pagestyle{empty}\cleardoublepage}
\chapter*{Conclusioni e sviluppi futuri}
\addcontentsline{toc}{chapter}{Conclusioni e sviluppi futuri}
In questa dissertazione sono state valutate due tecniche di sviluppo di applicazioni web real-time attualmente applicabili nei browser moderni. In particolare è stato fatto un confronto tra le caratteristiche delle più utilizzate tecniche client-pull, cioè polling e long polling, e server-push, cioè Server Sent Events e WebSockets.

Si è notato come le tecniche client-pull presentino problematiche date da un aumento della latenza e dell'utilizzo della banda di rete, e rendano l'applicazione di difficile scalabilità. Di contro, le tecniche server-push sfruttano in maniera efficiente il traffico dati e minimizzano i tempi di risposta.

\bigskip

È stato presentato \textit{ListenJS}, un progetto basato sul protocollo WebSocket atto a semplificare e migliorare sia l'esperienza utente che quella dello sviluppatore, offrendo funzionalità che sono implementate ad un livello più alto rispetto a quello dei WebSocket. Le librerie sviluppate, una client per tutti i browser moderni e una server per NodeJS, offrono un modo semplice di rimanere in ascolto di alcune risorse e di notificare i client degli aggiornamenti che subiscono.

Inoltre, il sistema fornisce funzionalità integrate come \textit{disconnection detection}, per capire quando si perde connettività con il server (o di contro, con il client), \textit{reconnection}, per riconnettersi automaticamente in caso di problemi di rete, e \textit{multiplexing}, per poter sfruttare la stessa connessione per ogni differente dominio.

È stato esposto il funzionamento a basso livello delle librerie e delle funzionalità implementate, per offrire una comprensione a tutto tondo e permettere di migliorare o ampliare il sistema.

\bigskip

Successivamente è stata presentata un'applicazione web di esempio che permette a diversi utenti di contribuire ad un calendario di appuntamenti in real-time. Sulla base di essa è stata fatta una valutazione qualitativa e quantitativa comparando le classiche tecniche di polling con i WebSocket, utilizzati dalle librerie.  Si è visto che in ogni caso un approccio basato sui WebSocket diminuisce la latenza media di notifica di aggiornamento delle risorse, diminuisce lo spreco della banda e favorisce la scalabilità.

In ultimo si è sottolineato come usando un sistema come ListenJS si possa semplificare l'utilizzo dei WebSocket senza costi di sviluppo aggiuntivi, portando a migliorare lo sviluppo, le performance, e conseguentemente l'esperienza utente.

\subsubsection{Sviluppi futuri}
ListenJS può essere estesa sotto diversi aspetti. In primis, si può gestire le \textit{connessioni su TLS}, e quindi permettere di eseguire l'handshake dei WebSocket tramite HTTPS.

Successivamente, è possibile diminuire ulteriormente l'utilizzo della banda tramite sistemi di \textit{delta messaging}: invece di inviare ogni volta l'intera risorsa aggiornata, si può pensare di inviare solo le modifiche effettuate su di essa, e dunque ogni client si occupa di ricostruire la nuova risorsa partendo dall'ultima salvata.

Infine, si potrebbe gestire una \textit{coda di messaggi} in modo da mantenere in sospeso i messaggi che non si riescono a recapitare ad un client per problemi di connettività, e tenerli in coda finché il client non riesce a riconnettersi.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
							% Bibliografia
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\clearpage{\pagestyle{empty}\cleardoublepage}

%\rhead[\fancyplain{}{\bfseries
%Bibliografia}]{\fancyplain{}{\bfseries\thepage}}
%\lhead[\fancyplain{}{\bfseries\thepage}]{\fancyplain{}{\bfseries
%Bibliografia}}

\bibliographystyle{unsrt}
\bibliography{bibliografia}
\addcontentsline{toc}{chapter}{Bibliografia}

\end{document}
